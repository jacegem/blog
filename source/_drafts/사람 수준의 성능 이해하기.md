# 사람 수준의 성능 이해하기

<https://www.edwith.org/deeplearningai3/lecture/34882/>

사람 수준의 성능이라는 용어는 연구 논문에서 큰 뜻 없이 쓰이곤 합니다

이번 시간에는 그 용어를 더 정확히 정의하고 사람 수준의 성능의 정의를 이용해서 머신러닝 프로젝트를 발전시켜 보겠습니다

![](https://monosnap.com/image/yH8egxIZnLvBQJLi4IjTYumLYWUSPa.png)

지난 영상에서 사람 수준의 오차라는 용어를 베이지안 오차의 추정치로 사용했던 것을 기억하실 겁니다

현재 또는 미래에 어떤 함수가 달성할 수 있는 최고의 오차값을 일컫죠

이걸 염두에 두고 의료 사진 분류 예시를 하나 살펴봅시다

이런 방사선 사진을 보고 있다고 합시다

이제 진단을 위한 분류를 할 차례입니다

![](https://monosnap.com/image/igYOgLx4gGlyqFQdJAX6FwsSV3HtRW.png)

훈련되지 않은 사람은 이 태스크에서 3%의 오차를 보이고

일반적인 의사, 방사선사는 1% 경험이 많은 의사는 나아가 0.7%의 오차를 보인다고 하죠

그리고 숙련된 의사들의 팀이 모두 사진을 본 뒤 논의를 거쳐

합의를 본 결과 0.5%의 오차를 보인다고 합시다

여기에서 던질 수 있는 질문은 사람 수준의 오차를 어떻게 정의할거냐는 겁니다

3%, 1%, 0.7%, 0.5% 중에 무엇일까요?

잠시 영상을 멈추고 한번 생각해보세요

팁을 하나 드리자면 사람 오차를 생각하는 좋은 방법은

베이지안 오차의 추정치로 보는 것입니다

잠시 영상을 멈추고 답을 생각해보세요

이건 제가 생각하는 인간 수준의 오차입니다

우선 베이지안 오차의 추정치를 생각했을 때

숙련된 의사들의 논의 결과로 얻어진 오차가 0.5%라면

베이지안 오차 역시 0.5%보다 작거나 같으리라고 생각할 수 있습니다

왜냐하면 의사들의 팀이 0.5%의 오차를 보였기 때문에

이론적으로 최적의 오차는 0.5%일테니까요

하지만 우리는 얼마나 나은 결과가 가능할지 알 수 없습니다

더 크고, 더 숙련된 의사들의 팀이라면 0.5%보다 더 작은 오차를 보일 수도 있을테니까요

최적 오차가 0.5%보다 크지 않으리란건 알 수 있습니다

이제 0.5%를 베이지안 오차의 추정치로 생각해보겠습니다

즉 사람 수준의 성능을 0.5%로 정의할 수 있습니다

지난 영상에서 봤던 것처럼

편향과 분산을 분석할 때 사람 수준의 오차를 쓸 수 있겠죠

이제 연구 논문을 쓰거나 시스템을 만들기 위해서는

사람 수준의 오차에 관한 또다른 오차가 있을 겁니다

만약 전형적인 의사의 성능을 뛰어넘는다면 아주 유용한 결과물이 될 겁니다

한 명의 방사선사, 의사의 성능을 넘는 것은

사용하기에 충분히 좋은 시스템을 뜻하죠

즉 사람 수준의 오차를 정의함에 있어서 목적이 무엇인지를 명확히 하는 것이 중요합니다

사람을 뛰어넘을 수 있기 때문에 어떤 맥락에서

시스템으로 사용할 수 있다고 주장한다면 이것이 적절한 정의가 될테지요

그러나 베이지안 오차에 대한 추정치가 목표라면 이것이 적절한 정의가 될 겁니다

이게 왜 중요한지 보기 위해 오차 분석 예시를 살펴봅시다

![](https://monosnap.com/image/CANOqjow1GH488Uq0EeEB6rMRXkjLK.png)

의료 사진 진단 예시에서 학습 오차가 5%이고 개발 오차가 6%라고 해봅시다

그리고 지난 슬라이드에서 사람 수준의 성능을 여기에서는 베이지안 오차의 추정치로 생각할 건데요

여러분이 그걸 일반적인 의사의 성능 또는 숙련된 의사, 의사 팀의 성능으로 보느냐에 따라 달려있겠죠

0.7% 또는 0.5%가 될 수 있겠습니다

그리고 지난 영상에서의 정의를 떠올려보죠

베이지안 오차, 또는 그 추정치와 학습 오차의 차이를 회피 가능 편향이라고 불렀고, 이 값은 학습 알고리즘에서 문제의 분산의 추정치를 가리켰습니다

첫 번째 예시에서 어떤 선택을 하든간에 회피 가능 편향은 4%쯤 될 겁니다

아마 이걸 사용하면 4% 0.5%를 사용하면 4.5%가 되겠죠?

반면에 이 값은 1%입니다

이 예시에서 사람 수준 오차의 정의를 무엇을 쓰든지 간에 일반적인 의사나 숙련된 의사의 오차 숙련된 의사의 팀의 오차를 사용하더라도 이 값은 4%와 4.5% 사이가 될 테고 확실히 분산보다 큽니다

이 경우에는 편향을 줄이기 위해 더 큰 신경망을 학습시키는 기술을 쓸 수 있겠죠

두 번째 예시를 살펴봅시다

학습 오차가 1%이고 개발 오차가 5%라고 하겠습니다

그러면 또다시 사람 수준의 성능이

1%, 0.7%, 0.5% 중 어떤 값이건 간에

즉 어떤 정의를 사용하건 간에

회피 가능 편향의 값은 아마 이걸 사용하면 0%가 될테고

이걸 사용하면 0.5%가 될 겁니다

사람 수준의 성능과 학습 오차의 차이죠

반면 이 차이는 4%에 달합니다

모든 경우에 4%가 회피 가능 편향보다 크죠

따라서 분산을 줄이는 기술에 초점을 둬야 합니다

정규화나 더 큰 학습 세트를 이용하는 거죠

하지만 정말 까다로운 경우는 학습 오차가 0.7%로 아주 좋은 성능을 보이고

개발 오차가 0.8%인 경우입니다

이 경우 베이지안 오차로 무엇을 사용하느냐가 정말로 중요하죠

만약 0.5%를 사용할 경우 회피 가능 편향은 0.2%로

0.1%의 분산의 두 배에 달합니다

이 경우 편향과 분산 모두 문제가 있지만

회피 가능 편향이 더 큰 문제겠죠?

지난 슬라이드에서 봤듯이 0.5%는 베이지안 오차의 최댓값입니다

의사의 팀이 달성한 수치니까요

만약 베이지안 오차의 추정치로 0.7%를 사용했다면

회피 가능 편향의 추정치는 0%에 가깝기 때문에

학습 세트에 대해 더 잘 학습을 했어야 할 겁니다

이 과정을 통해 왜 머신러닝 프로젝트에서

사람 수준의 성능에 다다를수록 더 좋은 성과를 내기 어려운지

감을 잡았기 바랍니다

이 예시에서 0.7%의 예시에 도달한 뒤

베이지안 오차를 조심스레 추정하지 않으면 얼마나 떨어져있는지 모를 겁니다

즉 회피 가능 편향을 얼마나 줄여야하는지 모르는 것이죠

만약 일반적인 의사가 보인 오차 1%를 사용했다면

학습 세트에 맞추기 위해 더 잘 학습해야하는지 알기 매우 어렵습니다

이 문제는 여러분이 문제를 잘 해결하고 있을 때 발생합니다

여기에서 0.7%, 0.8%처럼 사람 수준의 오차와 가까운 성능을 보일 때요

반면 사람 수준의 성능과 동떨어진 왼쪽의 두 예시에 대해서는

편향과 분산 중 어디에 초점을 맞춰야하는지 말하기 쉽죠

즉 이 도식을 통해서 왜 사람 수준의 성능에 가까워질수록

편향과 분산 중 무엇에 중점을 둘지 결정하기 어렵고

매우 잘 하고 있기 때문에 머신 러닝 프로젝트에서 더 나아가기도 어렵습니다

우리가 여태껏 얘기한 것을 요약해보죠

편향과 분산을 이야기할 때

사람이 매우 잘 하는 예시에서 사람 수준의 오차의 추정치를 알고 있으면

그걸 베이지안 오차의 추정치로 사용할 수 있습니다

그리고 베이지안 오차의 추정치와의 차이는 문제의 회피 가능 편향을 말해주고

개발 오차와 학습 오차의 차이는

문제의 분산을 말해줍니다

즉 학습 세트에 대해 학습시킨 알고리즘을

개발 세트로까지 일반화시킬 수 있냐는거죠

여기에서의 논의와 여태까지 수업에서 다뤘던 내용의 차이는

편향의 추정치라고 불렀던 학습 오차와 0%의 차이를 보는 대신

이 영상에서는 미묘한 차이가 있었습니다

결코 0%의 오차를 얻을 수 없는 분석을 했죠

왜냐하면 베이지안 오차는 0이 아니고 어떤 것도 그 오차의 문턱을 넘을 수 없으니까요

즉 수업 앞 부분에서는

학습 오차를 측정하고

학습 오차가 0에 대해 얼마나 큰지 본다음

그걸 토대로 편향이 얼마나 큰지를 봤습니다

베이지안 오차가 0%에 가까운 경우 잘 작동했습니다

예컨대 사람은 고양이 인지를 거의 정확히 하니까 베이지안 오차도 거의 0에 가깝죠

즉 베이지안 오차가 0에 가까우니 잘 작동하는 겁니다

하지만 음성 인식처럼 아주 잡음이 많은 데이터의 경우

들은 내용을 글로 옮기는 것 자체가 불가능할 수도 있습니다

이렇게 베이지안 오차를 갖고 있는 문제에서는

회피 가능 편향이나 분산의 추정치를 이용해

편향을 줄일지 분산을 줄일지 결정할 수 있습니다

다시 돌아보자면

사람 수준의 성능에 대한 추정치를 토대로

베이지안 오차를 추정할 수 있고

알고리즘의 편향을 줄일지 분산을 줄일지 더 빨리 결정할 수 있습니다

이 기술은 사람 수준의 성능을 능가할 때까지 잘 작동할 겁니다

이후에는 베이지안 오차에 대한 좋은 추정치를 갖고 있지 않으니

명확한 결정을 내릴 수 없죠

최근 딥러닝에서는 많은 태스크에서 사람 수준의 성능을

뛰어넘고 있습니다

다음 영상에서는 어떻게 사람 수준의 성능을 능가하는지 그 과정을 살펴봅시다



## **학습내용**

- 목적에 따라서 사람 수준의 오차를 베이지안 최적오차로 추정할 수있습니다.
- 의사의 예시에서 제일 경험이 많은 전문의의 오차를 베이지안 최적오차로 추정하게 된다면, 일반적인 진료 시스템에 사용하기 위해, 일반 의사의 오차를 사람 수준의 오차로 볼 수 있습니다. 이렇게 함으로써 머신러닝이 학습하게될 목적을 명확히 할 수 있습니다.
- 사람 수준의 오차를 베이지안 최적오차로 추정할 때, 사람 수준의 오차가 훈련오차보다 더 높지 않도록 설정하는 것을 주의해야 합니다.
- 분산은 개발 세트로 모델을 얼만큼 일반화 할 수 있는지를 알 수 있습니다. 차이가 적을 수록 새로운 데이터를 잘 예측 할 수 있습니다.